# Tech Layoffs ‚Äî End-to-End Data Cleaning & ETL Pipeline (Snowflake)

- Este projeto demonstra a constru√ß√£o de um pipeline completo de **Data Cleaning e ETL** utilizando **Snowflake** e a **Medallion Architecture (Bronze, Silver e Gold)**.  
- O objetivo √© transformar dados brutos e inconsistentes sobre layoffs em um dataset **confi√°vel, padronizado e pronto para an√°lises anal√≠ticas e BI**.

## Objetivo do Projeto
- Limpar e padronizar dados reais com m√∫ltiplas inconsist√™ncias.
- Garantir **qualidade, integridade e consist√™ncia** antes do consumo anal√≠tico.
- Construir um pipeline **reprodut√≠vel, idempotente e audit√°vel**.
- Simular um cen√°rio pr√≥ximo ao ambiente produtivo de dados.

## Stack Tecnol√≥gica
- **Plataforma:** Snowflake (Cloud Data Warehouse)
- **Linguagem:** SQL (CTEs, Window Functions, Defensive SQL)
- **Arquitetura:** Medallion Architecture (Bronze / Silver / Gold)

> A escolha do Snowflake se deu pela possibilidade de executar todo o pipeline sem billing ativo. A mesma estrutura funcionaria da mesma forma em BigQuery ou Redshift com pequenas adapta√ß√µes.
---

## üîÑ Arquitetura do Pipeline

### üü§ Camada Bronze ‚Äî Raw

Armazena os dados em seu estado original (`STG_LAYOFFS_RAW`), sem qualquer transforma√ß√£o.

**Principais problemas identificados:**
- Datas armazenadas como strings.
- Colunas num√©ricas com valores inv√°lidos.
- Strings como `'null'`, `'NULL'` e espa√ßos vazios representando valores nulos.
- Inconsist√™ncias de capitaliza√ß√£o, digita√ß√£o e categoriza√ß√£o.
- Registros duplicados.

### ‚ö™ Camada Silver ‚Äî Conformed

Camada respons√°vel pela **limpeza, padroniza√ß√£o e aplica√ß√£o de regras de neg√≥cio**.  
As transforma√ß√µes foram implementadas utilizando **CTEs encadeadas**, garantindo **legibilidade, modularidade e facilidade de auditoria**.

#### Principais Transforma√ß√µes

- **Padroniza√ß√£o de Nulos**  
  Convers√£o de strings inv√°lidas (`'null'`, `'NULL'`, espa√ßos em branco) em `NULL` real utilizando `TRIM()`.

- **Tipagem Defensiva de Dados**  
  Uso de `TRY_CAST` e `TRY_TO_DATE` para evitar falhas no pipeline causadas por dados inesperados.

- **Normaliza√ß√£o de Texto**  
  - `INITCAP()` para Company, Location, Industry e Country.  
  - `UPPER()` para Stage, garantindo consist√™ncia visual.

- **Imputa√ß√£o e Regras de Neg√≥cio**  
  Preenchimento manual de ind√∫strias ausentes para empresas espec√≠ficas:
  - Airbnb ‚Üí Travel  
  - Carvana ‚Üí Transportation  
  - Juul ‚Üí Consumer  

- **Corre√ß√£o de Inconsist√™ncias de Dom√≠nio**  
  - Unifica√ß√£o de categorias (`Cryptocurrency`, `Crypto Currency` ‚Üí `Crypto`).  
  - Corre√ß√£o de nomes de pa√≠ses (`United States.` ‚Üí `United States`).

- **Deduplica√ß√£o**  
  Remo√ß√£o de registros duplicados utilizando `ROW_NUMBER()` com `PARTITION BY` em todas as colunas relevantes, garantindo um resultado determin√≠stico.

### üü° Camada Gold ‚Äî Analytics

Camada final otimizada para consumo anal√≠tico.

- **Filtro de Relev√¢ncia**  
  Remo√ß√£o de registros sem m√©tricas essenciais (`Total_Laid_Off` e `Percentage_Laid_Off`).

- **Organiza√ß√£o Temporal**  
  Dados organizados cronologicamente, facilitando an√°lises hist√≥ricas, dashboards e relat√≥rios executivos.

> A camada Gold est√° pronta para integra√ß√£o com ferramentas de BI como Power BI ou Tableau.

---
## Estrutura do Script SQL

O pipeline da camada Silver foi organizado em CTEs, cada uma com uma responsabilidade clara:

1.  `cte1_standarize1`: Limpeza t√©cnica e tipagem defensiva.
2.  `cte2_standarize2`: Padroniza√ß√£o est√©tica e capitaliza√ß√£o.
3.  `cte3_imputation`: Regras de neg√≥cio e imputa√ß√µes manuais.
4.  `cte4_deduplicate`: Remo√ß√£o de duplicatas.

---

## Li√ß√µes Aprendidas

- Dados devem ser limpos **antes** da deduplica√ß√£o para garantir resultados corretos.
- `TRY_CAST` √© essencial para pipelines robustos em ambientes com dados reais.
- Separar limpeza t√©cnica de regras de neg√≥cio melhora a clareza e escalabilidade do c√≥digo.
- A Medallion Architecture facilita auditoria, versionamento e crescimento do projeto.

